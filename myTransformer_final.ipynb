{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariusLotz/myTransformerExp/blob/main/myTransformer_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a429510",
      "metadata": {
        "id": "9a429510",
        "lines_to_next_cell": 2,
        "tags": []
      },
      "source": [
        "\n",
        "<center><h1>The Annotated Transformer</h1> </center>\n",
        "\n",
        "\n",
        "<center>\n",
        "<p><a href=\"https://arxiv.org/abs/1706.03762\">Attention is All You Need\n",
        "</a></p>\n",
        "</center>\n",
        "\n",
        "<img src=\"https://github.com/harvardnlp/annotated-transformer/blob/master/images/aiayn.png?raw=1\" width=\"70%\"/>\n",
        "\n",
        "* adapted minimal version 2023: Marius Lotz\n",
        "* *[Original](https://nlp.seas.harvard.edu/2018/04/03/attention.html):\n",
        "   [Sasha Rush](http://rush-nlp.com/).*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd0e680",
      "metadata": {
        "id": "edd0e680"
      },
      "source": [
        "# Installing and importing modules:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b66397f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "b66397f7",
        "outputId": "a9689354-ce1d-4810-b014-32451a14bbfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Alle nötigen Downloads:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"Alle nötigen Downloads:\"\"\"\n",
        "#!pip install -q pandas==1.3.5\n",
        "#!pip install -q torch==1.11.0+cu113\n",
        "#!pip install -q torchdata==0.3.0\n",
        "#!pip install -q torchtext==0.12\n",
        "#!pip install -q spacy==3.2\n",
        "#!pip install -q altair==4.1\n",
        "#!pip install -q GPUtil\n",
        "#!pip install -q wandb\n",
        "#!pip install wget\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "84c7fa96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:17.544078Z",
          "iopub.status.busy": "2022-05-02T01:25:17.542981Z",
          "iopub.status.idle": "2022-05-02T01:25:17.545515Z",
          "shell.execute_reply": "2022-05-02T01:25:17.546285Z"
        },
        "id": "84c7fa96",
        "lines_to_next_cell": 2,
        "outputId": "9dc64026-c263-40f2-d4ec-8795361415ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.2.0 which is incompatible.\n",
            "inflect 6.0.4 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m2023-07-01 12:52:11.412164: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-01 12:52:12.633791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.2.0/de_core_news_sm-3.2.0-py3-none-any.whl#egg=de_core_news_sm==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting de-core-news-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.2.0/de_core_news_sm-3.2.0-py3-none-any.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.7.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.10.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.1.3)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "2023-07-01 12:52:22.917659: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-01 12:52:24.208955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl#egg=en_core_web_sm==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting en-core-web-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.5.0\n",
            "    Uninstalling en-core-web-sm-3.5.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.5.0\n",
            "Successfully installed en-core-web-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Nötige Downloads für Google-Colab: \"\"\"\n",
        "!pip install -q torchdata==0.3.0 torchtext==0.12 spacy==3.2 altair GPUtil wget # Module\n",
        "!python -m spacy download de_core_news_sm # spacy, deutsches Vokabular\n",
        "!python -m spacy download en_core_web_sm # spacey, englisches Vokabular\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1bf3deb7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:17.560273Z",
          "iopub.status.busy": "2022-05-02T01:25:17.559273Z",
          "iopub.status.idle": "2022-05-02T01:25:18.690005Z",
          "shell.execute_reply": "2022-05-02T01:25:18.690769Z"
        },
        "id": "1bf3deb7",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "\"\"\"Nötige Imports und Helper Funktionen:\"\"\"\n",
        "import os\n",
        "import wget\n",
        "from os.path import exists\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import log_softmax, pad\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torchtext.datasets as datasets\n",
        "import spacy\n",
        "import GPUtil\n",
        "import warnings\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "\n",
        "# Helpers:\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "RUN_EXAMPLES = True\n",
        "def show_example(fn, args=[]):\n",
        "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
        "        return fn(*args)\n",
        "\n",
        "def execute_example(fn, args=[]):\n",
        "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
        "        fn(*args)\n",
        "\n",
        "class DummyOptimizer(torch.optim.Optimizer):\n",
        "    def __init__(self):\n",
        "        self.param_groups = [{\"lr\": 0}]\n",
        "        None\n",
        "\n",
        "    def step(self):\n",
        "        None\n",
        "\n",
        "    def zero_grad(self, set_to_none=False):\n",
        "        None\n",
        "\n",
        "class DummyScheduler:\n",
        "    def step(self):\n",
        "        None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ffe7928",
      "metadata": {
        "id": "4ffe7928"
      },
      "source": [
        "# Part 1: Aufbau des Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "592fd662",
      "metadata": {
        "id": "592fd662",
        "lines_to_next_cell": 2
      },
      "source": [
        "<div>\n",
        "Der Transformer ist ein neuronales Netzwerkmodell, welchen in dem Paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762) im Jahr 2017 vorgestellt wurde. Es verwendet eine Attention-Mechanismus-basierte Architektur, um effektiv und parallel Informationen über die Eingabesequenz zu erfassen. Die Hauptkomponenten und Transformationsschritte eines Transformers lauten:\n",
        "\n",
        "1. Eingabeembeddings:\n",
        "Die Eingabesequenz besteht aus one-hot Vektoren, welche in Eingabeembeddings tranformiert werden.\n",
        "Hierbei findet eine Dimensionsreduktion statt.\n",
        "\n",
        "2. Positional Encoding:\n",
        "Da der Transformer keine Rekurrenz oder Faltung verwendet, wird eine Positionscodierung hinzugefügt (addiert), um die Positionsinformationen der Tokens in der Sequenz zu erfassen.\n",
        "\n",
        "\n",
        "</div>\n",
        "<div>\n",
        "<img src=\"https://github.com/harvardnlp/annotated-transformer/blob/master/images/ModalNet-21.png?raw=1\" align=\"left\" margin-right=\"20px\">\n",
        "</div>\n",
        "<div>\n",
        "\n",
        "3. Encoder (links):\n",
        "Der Encoder besteht aus mehreren (N) identischen Schichten, die als Encoder-Layer bezeichnet werden.\n",
        "Jeder Encoder-Layer enthält zwei Hauptsublayer:\n",
        "Multi-Head Attention und Feed-Forward Network (FFN).\n",
        "\n",
        "4. Multi-Head Attention:\n",
        "Die Multi-Head Attention ermöglicht dem Transformer, Beziehungen zwischen den Tokens in der Eingabesequenz zu modellieren.\n",
        "Sie besteht aus mehreren Attention-Heads, die parallel arbeiten und unterschiedliche Repräsentationen der Eingabesequenz lernen.\n",
        "Jeder Attention-Head berechnet gewichtete Aufmerksamkeitsvektoren, um die Bedeutung jedes Tokens in Bezug auf alle anderen Token zu bestimmen.\n",
        "\n",
        "5. Feed-Forward Network (FFN):\n",
        "Das FFN wird auf jedes Token in der Sequenz angewendet. Es ermöglicht dem Transformer, nichtlineare Transformationen auf die Repräsentation der Tokens durchzuführen.\n",
        "\n",
        "6. Residual Connection und Layer Normalization:\n",
        "Zwischen den Sublayern des Encoders werden Residual Connections und Layer Normalization angewendet, um stabiles und schnelles Lernen zu ermöglichen.\n",
        "Die Residual Connection fügt die Eingabe des Sublayers zu seiner Ausgabe hinzu, um Informationen von der Eingabe zu erhalten.\n",
        "Die Layer Normalization normalisiert die Ausgabe des Sublayers, um die Gradientenpropagation zu verbessern.\n",
        "\n",
        "7. Decoder (rechts): Der Decoder hat eine ähnliche Architektur wie der Encoder, besteht jedoch aus Decoder-Layern.\n",
        "Jeder Decoder-Layer enthält zusätzlich zur Multi-Head Attention und dem FFN eine weitere Multi-Head Attention-Schicht, die den Encoder-Output als Quelle verwendet.\n",
        "Die zusätzliche Multi-Head Attention ermöglicht dem Decoder, Informationen über den Kontext der Eingabesequenz zu berücksichtigen.\n",
        "\n",
        "8. Generator (rechts oben):\n",
        "Der Generator ist eine lineare Schicht, die die Ausgabe des Decoders in die endgültige Ausgabe umwandelt (PseudoInverse der Projektion).\n",
        "Sie führt eine Klassifikation oder eine Wahrscheinlichkeitsverteilung über das Vokabular durch, um das nächste Token in der Sequenz zu generieren.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MxdmY36heJAV",
      "metadata": {
        "id": "MxdmY36heJAV"
      },
      "source": [
        "## Attention-Funktion\n",
        "\n",
        "Die Eingabe $x$ des Transformers wird durch drei verschiedene lineare Transformationen $W^q, W^k, W^v$ weiterverarbeitet. Danach erhält man die Query-, Key- und Value-Vektoren mit denen man dann die kontextbezogenen Embeddings bestimmen kann, welche durch\n",
        "\n",
        "$$\n",
        "A_j = ∑_{i=1}^T \\frac{exp(a_{i,j})}{∑_{j=1}^T exp(a_{i,j})} \\cdot v_i\n",
        "$$\n",
        "\n",
        "bestimmt sind. Hierbei ist $v_i = x_i W^v$ und\n",
        "\n",
        "$$\n",
        "a_{i,j} = <q_i, k_j> = <x_i W^q, x_j W^k>.\n",
        "$$\n",
        "\n",
        "\n",
        "Diese Transformationen ermöglichen es dem Modell, die Beziehungen zwischen den Wörtern im Eingabesatz zu erfassen. Da Matrixmultiplikation schneller möglich ist als alle $A_j$ einzeln zu berechnen, werden alle alle Kontextbezogenen Embeddings mit Hilfe der unteren Matrix Multiplikation zusammen berechnet.\n",
        "\n",
        "\n",
        "$$\n",
        "   A= \\begin{pmatrix}\n",
        "A_1 \\\\\n",
        "... \\\\\n",
        "A_T \\\\\n",
        "\\end{pmatrix} = \\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "JlUwOhwUeZMl",
      "metadata": {
        "id": "JlUwOhwUeZMl"
      },
      "outputs": [],
      "source": [
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"\"\"Berechne die 'Scaled Dot Product Attention'\"\"\"\n",
        "    d_k = query.size(-1) # repräsentiert die Dimension der keys und queries\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k) # Teil in der softmax Funktion\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9) # Durch eine Maske geblockte Einträge erhalten ein sehr hohen negativen Attention Score\n",
        "    p_attn = scores.softmax(dim=-1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn) # Dropout beim Training\n",
        "    return torch.matmul(p_attn, value), p_attn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bpRtUT_2etA4",
      "metadata": {
        "id": "bpRtUT_2etA4"
      },
      "source": [
        "\n",
        "![](https://github.com/MariusLotz/myTransformerExp/raw/main/images/attention-raschka.png)\n",
        "\n",
        "<br>\n",
        "Im obigen Bild, wird nochmal die Berechnung auf Vektorebene veranschaulicht, hier für das kontextbezogene Embedding $A_2$.\n",
        "<br> <br>\n",
        "\n",
        "<hr color=\"red\">\n",
        "\n",
        "<br>\n",
        "Im unteren Bild, wird die Berechnung auf Matrixebene veranschaulicht. Man sieht die einzelnen Schritte für die Berechnung\n",
        "der Attention Matrix A.  \n",
        "<br>\n",
        "<br>\n",
        "\n",
        "![](https://github.com/MariusLotz/myTransformerExp/raw/main//images/attention3-raschka.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6005590",
      "metadata": {
        "id": "a6005590"
      },
      "source": [
        "## I/O Embedding & Positional Encoding\n",
        "<div>\n",
        "<img src=\"https://github.com/MariusLotz/myTransformerExp/raw/main/images/Embedding.png\" align=\"right\" margin-right=\"20px\">\n",
        "</div>\n",
        "<div>\n",
        "\n",
        "Jeder Token liegt vor dem Embedding als one-hot Vektor vor. Somit ist der Raum aller Token i.d.R extrem hochdimensional und muss daher auf einen kleineren Raum projeziert werden. Dieser Schritt wird Embedding genannt. Hierbei wird jeder one-hot Vektor durch eine erlernbare Embedding-Matrix auf seine stetige Repräsentation projeziert. Die Embeddings erfassen die semantische Bedeutung der Token und liefern eine informativere Darstellung für nachgelagerte Aufgaben. Im Paper sind alle Embeddings von der Dimension $d_{model} =512$.\n",
        "\n",
        "</div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "hsEYoOAtZyZ_",
      "metadata": {
        "id": "hsEYoOAtZyZ_"
      },
      "outputs": [],
      "source": [
        "class Embeddings(nn.Module):\n",
        "    \"\"\"Projektion der Sequenz in die Dimension d_model\"\"\"\n",
        "    def __init__(self, d_model, vocab): # d_model=512, vocab=Anzahl aller Token\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.lut = nn.Embedding(vocab, d_model)\n",
        "        # self.lut ist eine Instanz der nn.Embedding-Klasse, die als Embedding-Schicht fungiert\n",
        "        # Die Schicht projiziert die Token der Sequenz von einem one-hot kodierten Vektor in einen kontinuierlichen Embedding-Vektor im d_model-dimensionalen Raum\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forwardpass der Embedding Schicht\"\"\"\n",
        "        return self.lut(x) * math.sqrt(self.d_model) # Varianzreduktion / Normalisierung des Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P119mBXOZ0Zd",
      "metadata": {
        "id": "P119mBXOZ0Zd"
      },
      "source": [
        "Um ebenfalls die Reihenfolge der Wörter in den Sequenzen zu erfassen wird an die Embeddings noch ein kleiner Teil addiert, welcher gegeben ist durch: <br>\n",
        "$$PE_{(pos,2i)} = \\sin(pos / 10000^{2i/d_{\\text{model}}})$$\n",
        "\n",
        "$$PE_{(pos,2i+1)} = \\cos(pos / 10000^{2i/d_{\\text{model}}})$$\n",
        "<br>\n",
        "Hierbei ist $pos \\in \\{1, ..., T\\}$ die Position des Tokens in der Sequenz und $i \\in \\{1, ..., d_{model}\\}$  ist die Dimension der Embeddings, hier also $d_{model} = 512$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dfacc553",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:19.300508Z",
          "iopub.status.busy": "2022-05-02T01:25:19.299554Z",
          "iopub.status.idle": "2022-05-02T01:25:19.301927Z",
          "shell.execute_reply": "2022-05-02T01:25:19.302701Z"
        },
        "id": "dfacc553"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout) #  Dropout-Schicht\n",
        "\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        # Die Positionsencodings werden einmalig in logarithmischen Raum berechnet:\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forwardpass der PositionalEnconding Schicht\"\"\"\n",
        "        # Die Positionsencodings werden addiert:\n",
        "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lXj4AaFeNIiC",
      "metadata": {
        "id": "lXj4AaFeNIiC"
      },
      "source": [
        "###Add & Norm  \n",
        "<div>\n",
        "<img src=\"https://github.com/MariusLotz/myTransformerExp/raw/main/images/SkipLayer.png\" align=\"left\" padding-right=\"40px\">\n",
        "</div>\n",
        "<div>\n",
        "\n",
        "Der Input x des Sublayers wird zu\n",
        "\n",
        "<br>\n",
        "$$LayerNorm(x+Sublayer(x))$$ <br>\n",
        "\n",
        "transformiert, wobei Sublayer die Funktion des Sublayers selbst ist.\n",
        "\n",
        "\n",
        "Die möglichen Sublayer hier sind Multi-Head Attention Layer und Feed-Forward Layer.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3db97336",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:18.779893Z",
          "iopub.status.busy": "2022-05-02T01:25:18.778804Z",
          "iopub.status.idle": "2022-05-02T01:25:18.780994Z",
          "shell.execute_reply": "2022-05-02T01:25:18.781710Z"
        },
        "id": "3db97336"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"\"\"Implementierung der Layer Normalisierung\"\"\"\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forwardpass der LayerNorm Schicht\"\"\"\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "\n",
        "class SublayerConnection(nn.Module):\n",
        "    \"\"\"Implementierung der Skip-Connection Verbindung\"\"\"\n",
        "\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        \"\"\"Forward Pass der Skip-Connection\"\"\"\n",
        "        return x + self.dropout(sublayer(self.norm(x))) # wieder mit Dropout-Schicht"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EV4zUWpvc0Tw",
      "metadata": {
        "id": "EV4zUWpvc0Tw"
      },
      "source": [
        "## Multi-Head Attention Layer\n",
        "\n",
        "Das Multi-Head Attention Layer zerlegt die Eingabe in mehrere Teilsequenzen gleicher Länge. Im Paper sind es 8 Köpfe, dh.\n",
        "jede Teilsequenz hat die Länge $d_v' = \\frac{d_v}{h} = \\frac{512}{8} = 64 $. Für jede Teilsequenz wird die Attention Matrix berechnet.\n",
        "Die \"Aufmerksamkeitsköpfe\" arbeiten parallel. Sie werden eingesetzt um verschiedene Darstellungen der Eingabe zu erlernen. Jeder Kopf führt eine eigenständige Attention-Berechnung durch.\n",
        "Danach werden alle Attention Matrizen aneinandergehängt, sodass wir wieder die Ausgangsgröße $d_v$ erhalten (\"Concat\" in der Abbildung)\n",
        "Die zusammengefügte Attention Matrix wird danach mit einer (erlernbaren) Matrix multipliziert (\"Linear\" in der Abbildung).\n",
        "<div>\n",
        "<img src=\"https://github.com/MariusLotz/myTransformerExp/raw/main/images/attention4-raschka.png\" align=\"left\" margin-right=\"20px\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "yGMq738kdAmZ",
      "metadata": {
        "id": "yGMq738kdAmZ"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        \"Take in model size and number of heads.\"\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0 # Dimension d_model muss durch h teilbar sein\n",
        "        # Es wird angenommen d_v ist auch immer gleich d_k\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h # Anzahl Köpfe\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"\"\"Forwardpass des Multi-Head Attention Layers\"\"\"\n",
        "        if mask is not None:\n",
        "            # Maske wird auf alle Köpfe angewandt\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        # 1) Berechnung aller querys, keys und values:\n",
        "        query, key, value = [\n",
        "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "            for lin, x in zip(self.linears, (query, key, value))\n",
        "        ]\n",
        "\n",
        "        # 2) Berechnung aller Attention Matrizen:\n",
        "        x, self.attn = attention(\n",
        "            query, key, value, mask=mask, dropout=self.dropout\n",
        "        )\n",
        "\n",
        "        # 3) Aneinanderhängen aller Attention Matrizen:\n",
        "        x = (\n",
        "            x.transpose(1, 2)\n",
        "            .contiguous()\n",
        "            .view(nbatches, -1, self.h * self.d_k)\n",
        "        )\n",
        "        # Speicher freimachen:\n",
        "        del query\n",
        "        del key\n",
        "        del value\n",
        "        return self.linears[-1](x) # Attention Matrix wird linear abgebildet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ht_t816_N2U1",
      "metadata": {
        "id": "ht_t816_N2U1"
      },
      "source": [
        "## Feed-Forward Layer\n",
        " Das Feed-Forward Layer wird auf jede Position der Eingabesequenz (Token) einzeln angewandt. Hierbei wird jeder Token x zu\n",
        "\n",
        "<br>\n",
        "$$ FFN(x) = max(0, xW_1)W_2 + b_2 $$\n",
        "<br>\n",
        "\n",
        "transformiert.\n",
        "Die Dimension eines jeden Token im Paper ist $d_{model}=512$. <br>\n",
        "Für jedes der $N=6$ Layer werden unterschiedliche Gewichte und Bias berechnet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "m9lWXxg1RMoO",
      "metadata": {
        "id": "m9lWXxg1RMoO"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"\"\"Implementierung des Feed-Forward NN\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forwardpass des NN\"\"\"\n",
        "        return self.w_2(self.dropout(self.w_1(x).relu())) # wieder mit Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sWQasE-sFKAf",
      "metadata": {
        "id": "sWQasE-sFKAf"
      },
      "source": [
        "## Aufbau des Transformers\n",
        "Der Transformer besteht neben den Embedding Schichten aus dem\n",
        "Encoder, Decoder und Generator, welche hier definiert werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "iNNfda-LhhCo",
      "metadata": {
        "id": "iNNfda-LhhCo"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(nn.Module): # Klasse erbt von nn.Module\n",
        "    \"\"\"Vanilla Encoder-Decoder Architektur\"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder # Encoder Teil\n",
        "        self.decoder = decoder # Decoder Teil\n",
        "        self.src_embed = src_embed # Input Encoder (Embedding)\n",
        "        self.tgt_embed = tgt_embed # Input Decoder (Embedding)\n",
        "        self.generator = generator # Output Decoder\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        \"\"\"Forward Pass des Transformers\"\"\"\n",
        "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        \"\"\"Forwardpass encode\"\"\"\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        \"\"\"Forwardpass decode\"\"\"\n",
        "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"'Pseudoinverse' der Projektion\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return log_softmax(self.proj(x), dim=-1) # Wahrscheinlichkeitsmaß\n",
        "\n",
        "def clones(module, N):\n",
        "    \"\"\"Erzeugt N identische Klone des Eingabe Layers=module\"\"\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sdYScTwJhcbI",
      "metadata": {
        "id": "sdYScTwJhcbI"
      },
      "source": [
        "### Encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "90e7e57e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:18.716980Z",
          "iopub.status.busy": "2022-05-02T01:25:18.716023Z",
          "iopub.status.idle": "2022-05-02T01:25:18.718971Z",
          "shell.execute_reply": "2022-05-02T01:25:18.718190Z"
        },
        "id": "90e7e57e"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encoder ist ein Stack von N Layers\"\"\"\n",
        "\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"Input wird durch alle Layer geschickt\"\"\"\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"Encoder besteht aus dem Attention Layer und dem FFN, sowie einem Dropout Layer beim Lernen\"\"\"\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"Forwardpass des Encoder Layers\"\"\"\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.feed_forward)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SBNKCcfJikLS",
      "metadata": {
        "id": "SBNKCcfJikLS"
      },
      "source": [
        "### Decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a2mAU7HeimIu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "a2mAU7HeimIu",
        "outputId": "d63ac0ed-193d-46a7-93f8-bdd075aa586d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beispielmaske\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-0d6ce86cc93748e4af8a21a7d77c4be7\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-0d6ce86cc93748e4af8a21a7d77c4be7\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-0d6ce86cc93748e4af8a21a7d77c4be7\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-ac10fa76400c18dafea2d104267bb03d\"}, \"mark\": \"rect\", \"encoding\": {\"color\": {\"field\": \"Subsequent Mask\", \"scale\": {\"scheme\": \"viridis\"}, \"type\": \"quantitative\"}, \"x\": {\"field\": \"Window\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Masking\", \"type\": \"ordinal\"}}, \"height\": 250, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 250, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-ac10fa76400c18dafea2d104267bb03d\": [{\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 0}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 1, \"Masking\": 0}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 2, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 2, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 16}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 18, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 18, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 16}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 17}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 19, \"Masking\": 19}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"Decoder ist ein Stack von N Layers mit Maske.\"\"\"\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        \"\"\"Input wird durch alle Layer geschickt\"\"\"\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"Decoder besteht aus dem Self-Attention Layer, dem Source Attention Layer und dem FFN, sowie einem Dropout Layer beim Lernen\"\"\"\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        \"Forwardpass des Decoder Laayers\"\"\"\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
        "        return self.sublayer[2](x, self.feed_forward)\n",
        "\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    \"\"\"Maskiere nachfolgende Positionen, damit der Tranformer beim Training nicht schummeln kann\"\"\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
        "        torch.uint8\n",
        "    )\n",
        "    return subsequent_mask == 0\n",
        "\n",
        "\n",
        "def example_mask():\n",
        "    \"\"\"Beispiel für eine subsequent_mask\"\"\"\n",
        "    LS_data = pd.concat(\n",
        "        [\n",
        "            pd.DataFrame(\n",
        "                {\n",
        "                    \"Subsequent Mask\": subsequent_mask(20)[0][x, y].flatten(),\n",
        "                    \"Window\": y,\n",
        "                    \"Masking\": x,\n",
        "                }\n",
        "            )\n",
        "            for y in range(20)\n",
        "            for x in range(20)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        alt.Chart(LS_data)\n",
        "        .mark_rect()\n",
        "        .properties(height=250, width=250)\n",
        "        .encode(\n",
        "            alt.X(\"Window:O\"),\n",
        "            alt.Y(\"Masking:O\"),\n",
        "            alt.Color(\"Subsequent Mask:Q\", scale=alt.Scale(scheme=\"viridis\")),\n",
        "        )\n",
        "        .interactive()\n",
        "    )\n",
        "\n",
        "\n",
        "print(\"Beispielmaske\")\n",
        "show_example(example_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JVnvl15sjpf-",
      "metadata": {
        "id": "JVnvl15sjpf-"
      },
      "source": [
        "### Modell erstellen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a7f34584",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:18.767044Z",
          "iopub.status.busy": "2022-05-02T01:25:18.766174Z",
          "iopub.status.idle": "2022-05-02T01:25:18.768689Z",
          "shell.execute_reply": "2022-05-02T01:25:18.769383Z"
        },
        "id": "a7f34584"
      },
      "outputs": [],
      "source": [
        "def make_model(src_vocab, tgt_vocab, N=6,\n",
        "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    \"\"\"\n",
        "    src_vocab = Anzahl der Token im Eingabetext\n",
        "    tgt_vocab = Anzahl der Token im Ausgabetext\n",
        "    N = Anzahl Schichten Encoder / Decoder\n",
        "    d_model = Dimension des Embeddings\n",
        "    d_ff = Dimension der Feedforward Schicht\n",
        "    h = Anzahl der Attention Heads\n",
        "    dropout = Dropout Rate für alle Schichten\n",
        "    \"\"\"\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(h, d_model) # Attention Funktion\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout) # Feed Forward NN Funktion\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "    model = EncoderDecoder( # Definition des Tranformers\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn),\n",
        "                             c(ff), dropout), N),\n",
        "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "        Generator(d_model, tgt_vocab))\n",
        "\n",
        "    # Bestimmte Initalisierung der Parameter:\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform(p)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6T_Wl_cLvZuW",
      "metadata": {
        "id": "6T_Wl_cLvZuW"
      },
      "source": [
        "# Part 2: Training des Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ECqfcmAK0B6f",
      "metadata": {
        "id": "ECqfcmAK0B6f"
      },
      "source": [
        "## Definition des Trainingsmodells\n",
        "Es werden einige der Werkzeuge eingeführt, die benötigt werden, um ein Standard-Encoder-Decoder-Modell zu trainieren.\n",
        "Diese umfassen die Definition eines Batches, einer Verlustfunktion, einer Lernrate sowie die Funktion TrainState und Label Smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "nGJwx6Ya0AKz",
      "metadata": {
        "id": "nGJwx6Ya0AKz"
      },
      "outputs": [],
      "source": [
        "class Batch:\n",
        "    \"\"\"Organisation und Verarbeitung einer Datencharge für das Training im Transformer-Modell\"\"\"\n",
        "\n",
        "    def __init__(self, src, tgt=None, pad=2):  # 2 = <blank>\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2) # Maske für die Quellsequenz\n",
        "        if tgt is not None:\n",
        "            # speichert die Zielsequenz ohne das letzte Token\n",
        "            # Dadurch wird eine Verschiebung um einen Schritt erreicht, um das Modell zu trainieren, das nächste Token vorherzusagen:\n",
        "            self.tgt = tgt[:, :-1]\n",
        "            # speichert die Zielsequenz ohne das erste Token\n",
        "            # Dies dient dazu, das Modell zu trainieren, das jeweils nächste Token vorherzusagen.\n",
        "            self.tgt_y = tgt[:, 1:]\n",
        "            self.tgt_mask = self.make_std_mask(self.tgt, pad) # Maske für die Zielsequenz, die sowohl Padding-Elemente als auch zukünftige Wörter blockiert\n",
        "            self.ntokens = (self.tgt_y != pad).data.sum()  # Anzahl der nicht-Padding-Token in der Zielsequenz\n",
        "\n",
        "    @staticmethod\n",
        "    def make_std_mask(tgt, pad):\n",
        "        \"Standardmaske die Padding und zukünftige Wörter blockt.\"\n",
        "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(\n",
        "            tgt_mask.data\n",
        "        )\n",
        "        return tgt_mask\n",
        "\n",
        "\n",
        "class SimpleLossCompute:\n",
        "    \"Loss Funktion .\"\n",
        "\n",
        "    def __init__(self, generator, criterion):\n",
        "        self.generator = generator # Ausgabe Generator bestimmt den Verlust beim Training\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        \"\"\"Berechnung des Verlusts nach dem Kriterium (criterion)\"\"\"\n",
        "        x = self.generator(x)\n",
        "        sloss = (\n",
        "            self.criterion(\n",
        "                x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)\n",
        "            )\n",
        "            / norm\n",
        "        )\n",
        "        return sloss.data * norm, sloss\n",
        "\n",
        "\n",
        "class TrainState:\n",
        "    \"\"\"Klasse dient dazu den Fortschritt des Trainingsprozesses zu verfolgen.\"\"\"\n",
        "\n",
        "    step: int = 0  # Steps in the current epoch\n",
        "    accum_step: int = 0  # Number of gradient accumulation steps\n",
        "    samples: int = 0  # total # of examples used\n",
        "    tokens: int = 0  # total # of tokens processed\n",
        "\n",
        "\n",
        "def run_epoch(\n",
        "    data_iter, # der Dateniterator\n",
        "    model, # zu trainierendes Modell\n",
        "    loss_compute, # Verlustfunktion\n",
        "    optimizer, # Gradientenverfahren z.B. Adam\n",
        "    scheduler, # der Lernratenplaner\n",
        "    mode=\"train\",\n",
        "    accum_iter=1, # die Anzahl der Gradientenakkumulationsschritte\n",
        "    train_state=TrainState(),\n",
        "):\n",
        "    \"\"\"Eine Epoche Training\"\"\"\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    tokens = 0\n",
        "    n_accum = 0\n",
        "    for i, batch in enumerate(data_iter):\n",
        "        out = model.forward(\n",
        "            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n",
        "        )\n",
        "        loss, loss_node = loss_compute(out, batch.tgt_y, batch.ntokens)\n",
        "        # loss_node = loss_node / accum_iter\n",
        "        if mode == \"train\" or mode == \"train+log\":\n",
        "            loss_node.backward()\n",
        "            # Trainingszustand wird aktualisiert\n",
        "            train_state.step += 1\n",
        "            train_state.samples += batch.src.shape[0]\n",
        "            train_state.tokens += batch.ntokens\n",
        "            if i % accum_iter == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                n_accum += 1\n",
        "                train_state.accum_step += 1\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss # Gesamtverlust wird aktualisiert\n",
        "        total_tokens += batch.ntokens # Gesamtanzahl Token werden aktualisiert\n",
        "        tokens += batch.ntokens\n",
        "        if i % 40 == 1 and (mode == \"train\" or mode == \"train+log\"):\n",
        "            lr = optimizer.param_groups[0][\"lr\"]\n",
        "            elapsed = time.time() - start\n",
        "            print(\n",
        "                (\n",
        "                    \"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f \"\n",
        "                    + \"| Tokens / Sec: %7.1f | Learning Rate: %6.1e\"\n",
        "                )\n",
        "                % (i, n_accum, loss / batch.ntokens, tokens / elapsed, lr)\n",
        "            )\n",
        "            start = time.time()\n",
        "            tokens = 0\n",
        "        del loss\n",
        "        del loss_node\n",
        "        # Rückgabe des durchschnittliche Verlust pro Token zusammen mit dem Trainingsstatus:\n",
        "    return total_loss / total_tokens, train_state\n",
        "\n",
        "\n",
        "def rate(step, model_size, factor, warmup):\n",
        "    \"\"\"Lernrate für einen bestimmten Schritt in der Trainingsphase eines Transformer-Modells\"\"\"\n",
        "    if step == 0:\n",
        "        step = 1 # wegen Formel unten (nicht durch 0 teilen)\n",
        "    return factor * (\n",
        "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
        "    )\n",
        "\n",
        "\n",
        "class LabelSmoothing(nn.Module):\n",
        "    \"\"\"\n",
        "    Label-Smoothing ersetzt den one-hot-kodierten Label-Vektor y_hot durch eine Mischung aus y_hot und einer gleichmäßigen Verteilung:\n",
        "    y_ls = (1 - α) * y_hot + α / K\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.criterion = nn.KLDivLoss(reduction=\"sum\") # Verlustfunktion\n",
        "        self.padding_idx = padding_idx\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.size = size\n",
        "        self.true_dist = None\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        \"\"\"Forwardpass des LabelSmoothing\"\"\"\n",
        "        assert x.size(1) == self.size\n",
        "        true_dist = x.data.clone()\n",
        "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
        "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        true_dist[:, self.padding_idx] = 0\n",
        "        mask = torch.nonzero(target.data == self.padding_idx)\n",
        "        if mask.dim() > 0:\n",
        "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "        self.true_dist = true_dist\n",
        "        return self.criterion(x, true_dist.clone().detach())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mZAD9MVqozDw",
      "metadata": {
        "id": "mZAD9MVqozDw"
      },
      "source": [
        "## Laden des Trainingssets\n",
        "\n",
        "In diesem Teil wird das Trainingsset und die Trainingbatches erstellt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "aA1c0YVDnWJG",
      "metadata": {
        "id": "aA1c0YVDnWJG"
      },
      "outputs": [],
      "source": [
        "def load_tokenizers():\n",
        "    \"\"\"Lade das spacy Modul für das Tokenisieren\"\"\"\n",
        "    try:\n",
        "        spacy_de = spacy.load(\"de_core_news_sm\")\n",
        "    except IOError:\n",
        "        os.system(\"python -m spacy download de_core_news_sm\")\n",
        "        spacy_de = spacy.load(\"de_core_news_sm\")\n",
        "\n",
        "    try:\n",
        "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "    except IOError:\n",
        "        os.system(\"python -m spacy download en_core_web_sm\")\n",
        "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    return spacy_de, spacy_en\n",
        "\n",
        "\n",
        "def tokenize(text, tokenizer):\n",
        "    \"\"\"Hilfsfunktion für den Tokenisierer\"\"\"\n",
        "    return [tok.text for tok in tokenizer.tokenizer(text)]\n",
        "\n",
        "\n",
        "def yield_tokens(data_iter, tokenizer, index):\n",
        "    \"\"\"Hilfsfunktion für den Tokenisierer\"\"\"\n",
        "    for from_to_tuple in data_iter:\n",
        "        yield tokenizer(from_to_tuple[index])\n",
        "\n",
        "\n",
        "def build_vocabulary(spacy_de, spacy_en):\n",
        "    \"\"\"Tokenisiere das Vocabular\"\"\"\n",
        "    def tokenize_de(text):\n",
        "        return tokenize(text, spacy_de)\n",
        "\n",
        "    def tokenize_en(text):\n",
        "        return tokenize(text, spacy_en)\n",
        "\n",
        "    print(\"Building German Vocabulary ...\")\n",
        "    train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
        "    vocab_src = build_vocab_from_iterator(\n",
        "        yield_tokens(train + val + test, tokenize_de, index=0),\n",
        "        min_freq=2,\n",
        "        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n",
        "    )\n",
        "\n",
        "    print(\"Building English Vocabulary ...\")\n",
        "    train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
        "    vocab_tgt = build_vocab_from_iterator(\n",
        "        yield_tokens(train + val + test, tokenize_en, index=1),\n",
        "        min_freq=2,\n",
        "        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n",
        "    )\n",
        "\n",
        "    vocab_src.set_default_index(vocab_src[\"<unk>\"])\n",
        "    vocab_tgt.set_default_index(vocab_tgt[\"<unk>\"])\n",
        "\n",
        "    return vocab_src, vocab_tgt\n",
        "\n",
        "\n",
        "# Vokabelm manuell runterladen anstatt zu erzeugen:\n",
        "#url_pt = \"https://github.com/MariusLotz/myTransformerExp/blob/main/vocab.pt\"\n",
        "#file_path = wget.download(url_pt)\n",
        "#print(\"downloaded vocab is used\")\n",
        "\n",
        "\n",
        "def load_vocab(spacy_de, spacy_en):\n",
        "    if not exists(\"vocab.pt\"):\n",
        "        vocab_src, vocab_tgt = build_vocabulary(spacy_de, spacy_en)\n",
        "        torch.save((vocab_src, vocab_tgt), \"vocab.pt\")\n",
        "    else:\n",
        "        vocab_src, vocab_tgt = torch.load(\"vocab.pt\")\n",
        "    print(\"Finished.\\nVocabulary sizes:\")\n",
        "    print(len(vocab_src))\n",
        "    print(len(vocab_tgt))\n",
        "    return vocab_src, vocab_tgt\n",
        "\n",
        "\n",
        "def collate_batch(\n",
        "    batch,\n",
        "    src_pipeline,\n",
        "    tgt_pipeline,\n",
        "    src_vocab,\n",
        "    tgt_vocab,\n",
        "    device,\n",
        "    max_padding=128,\n",
        "    pad_id=2,\n",
        "):\n",
        "    \"\"\"Batch Preprocessing: tokenization und padding->Ganzzahl-Tensoren\"\"\"\n",
        "    bs_id = torch.tensor([0], device=device)  # <s> token id\n",
        "    eos_id = torch.tensor([1], device=device)  # </s> token id\n",
        "    src_list, tgt_list = [], []\n",
        "    for (_src, _tgt) in batch:\n",
        "        processed_src = torch.cat(\n",
        "            [\n",
        "                bs_id,\n",
        "                torch.tensor(\n",
        "                    src_vocab(src_pipeline(_src)),\n",
        "                    dtype=torch.int64,\n",
        "                    device=device,\n",
        "                ),\n",
        "                eos_id,\n",
        "            ],\n",
        "            0,\n",
        "        )\n",
        "        processed_tgt = torch.cat(\n",
        "            [\n",
        "                bs_id,\n",
        "                torch.tensor(\n",
        "                    tgt_vocab(tgt_pipeline(_tgt)),\n",
        "                    dtype=torch.int64,\n",
        "                    device=device,\n",
        "                ),\n",
        "                eos_id,\n",
        "            ],\n",
        "            0,\n",
        "        )\n",
        "        src_list.append(\n",
        "            # warning - overwrites values for negative values of padding - len\n",
        "            pad(\n",
        "                processed_src,\n",
        "                (\n",
        "                    0,\n",
        "                    max_padding - len(processed_src),\n",
        "                ),\n",
        "                value=pad_id,\n",
        "            )\n",
        "        )\n",
        "        tgt_list.append(\n",
        "            pad(\n",
        "                processed_tgt,\n",
        "                (0, max_padding - len(processed_tgt)),\n",
        "                value=pad_id,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    src = torch.stack(src_list)\n",
        "    tgt = torch.stack(tgt_list)\n",
        "    return (src, tgt)\n",
        "\n",
        "\n",
        "def create_dataloaders(\n",
        "    device,\n",
        "    vocab_src,\n",
        "    vocab_tgt,\n",
        "    spacy_de,\n",
        "    spacy_en,\n",
        "    batch_size=12000,\n",
        "    max_padding=128,\n",
        "    is_distributed=True,\n",
        "):\n",
        "    # Erstelle Trainings- und Validierungsdatenlader mit Batch_size=12000:\n",
        "    def tokenize_de(text):\n",
        "        return tokenize(text, spacy_de)\n",
        "\n",
        "    def tokenize_en(text):\n",
        "        return tokenize(text, spacy_en)\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        return collate_batch(\n",
        "            batch,\n",
        "            tokenize_de,\n",
        "            tokenize_en,\n",
        "            vocab_src,\n",
        "            vocab_tgt,\n",
        "            device,\n",
        "            max_padding=max_padding,\n",
        "            pad_id=vocab_src.get_stoi()[\"<blank>\"],\n",
        "        )\n",
        "\n",
        "    train_iter, valid_iter, test_iter = datasets.Multi30k(\n",
        "        language_pair=(\"de\", \"en\")\n",
        "    )\n",
        "\n",
        "    train_iter_map = to_map_style_dataset(\n",
        "        train_iter\n",
        "    )  # DistributedSampler needs a dataset len()\n",
        "    train_sampler = (\n",
        "        DistributedSampler(train_iter_map) if is_distributed else None\n",
        "    )\n",
        "    valid_iter_map = to_map_style_dataset(valid_iter)\n",
        "    valid_sampler = (\n",
        "        DistributedSampler(valid_iter_map) if is_distributed else None\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_iter_map,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(train_sampler is None),\n",
        "        sampler=train_sampler,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "    valid_dataloader = DataLoader(\n",
        "        valid_iter_map,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(valid_sampler is None),\n",
        "        sampler=valid_sampler,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "    return train_dataloader, valid_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1nfJIiI0SPT",
      "metadata": {
        "id": "d1nfJIiI0SPT"
      },
      "source": [
        "###Modell trainieren:\n",
        "\n",
        "![](https://github.com/MariusLotz/myTransformerExp/raw/main/images/Translation.png)\n",
        "\n",
        "Im Folgenden wird das Modell trainiert (bzw. geladen). Auskommentieren von (Laden) führt dazu, dass das Modell neu trainiert wird, was bis zu einer halben Stunde dauern kann."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "xsRng3V4vkna",
      "metadata": {
        "id": "xsRng3V4vkna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f72650-ac38-4ead-f0ab-e2b74fe15e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished.\n",
            "Vocabulary sizes:\n",
            "8315\n",
            "6384\n"
          ]
        }
      ],
      "source": [
        "# Im Moment nicht auskommentieren, sondern multi30k_model_final.pt manuell hochladen\n",
        "# Laden (auskommentieren, wenn Modell neu berechnet werden soll):\n",
        "# url_pt = \"https://github.com/MariusLotz/myTransformerExp/blob/main/data/multi30k_model_final.pt\"\n",
        "# file_path = wget.download(url_pt)\n",
        "\n",
        "\n",
        "# Globale Variablen\n",
        "spacy_de, spacy_en = show_example(load_tokenizers)\n",
        "vocab_src, vocab_tgt = show_example(load_vocab, args=[spacy_de, spacy_en])\n",
        "\n",
        "\n",
        "def train_worker(\n",
        "    gpu,\n",
        "    ngpus_per_node,\n",
        "    vocab_src,\n",
        "    vocab_tgt,\n",
        "    spacy_de,\n",
        "    spacy_en,\n",
        "    config,\n",
        "    is_distributed=False,\n",
        "):\n",
        "    \"\"\"Definition des Trainingsprozess für einen einzelnen Worker\"\"\"\n",
        "    print(f\"Train worker process using GPU: {gpu} for training\", flush=True)\n",
        "    torch.cuda.set_device(gpu) #  GPU wird festgelegt\n",
        "\n",
        "    pad_idx = vocab_tgt[\"<blank>\"] # Padding\n",
        "    d_model = 512 # Dimension Embedding\n",
        "    model = make_model(len(vocab_src), len(vocab_tgt), N=6) # Erstellen des Transformers\n",
        "    model.cuda(gpu) # Festlegen GPU wird festgelegt\n",
        "    module = model\n",
        "    is_main_process = True\n",
        "    if is_distributed:\n",
        "        dist.init_process_group(\n",
        "            \"nccl\", init_method=\"env://\", rank=gpu, world_size=ngpus_per_node\n",
        "        )\n",
        "        model = DDP(model, device_ids=[gpu])\n",
        "        module = model.module\n",
        "        is_main_process = gpu == 0\n",
        "\n",
        "    criterion = LabelSmoothing( # Label Smoothing wird initialisiert\n",
        "        size=len(vocab_tgt), padding_idx=pad_idx, smoothing=0.1\n",
        "    )\n",
        "    criterion.cuda(gpu) # auf GPU gelegt\n",
        "\n",
        "    train_dataloader, valid_dataloader = create_dataloaders( # Trainings- und Validierungsdataloader\n",
        "        gpu,\n",
        "        vocab_src,\n",
        "        vocab_tgt,\n",
        "        spacy_de,\n",
        "        spacy_en,\n",
        "        batch_size=config[\"batch_size\"] // ngpus_per_node,\n",
        "        max_padding=config[\"max_padding\"],\n",
        "        is_distributed=is_distributed,\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam( # Auswahl Gradientenabstiegsverfahren\n",
        "        model.parameters(), lr=config[\"base_lr\"], betas=(0.9, 0.98), eps=1e-9\n",
        "    )\n",
        "    lr_scheduler = LambdaLR( # Auswahl Lernrate\n",
        "        optimizer=optimizer,\n",
        "        lr_lambda=lambda step: rate(\n",
        "            step, d_model, factor=1, warmup=config[\"warmup\"]\n",
        "        ),\n",
        "    )\n",
        "    train_state = TrainState() # Zustand des Trainingsvorgangs\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        if is_distributed: # Verteiltes Lernen:\n",
        "            train_dataloader.sampler.set_epoch(epoch)\n",
        "            valid_dataloader.sampler.set_epoch(epoch)\n",
        "\n",
        "        model.train() # Nicht verteiltes Lernen:\n",
        "        print(f\"[GPU{gpu}] Epoch {epoch} Training ====\", flush=True)\n",
        "        _, train_state = run_epoch(\n",
        "            (Batch(b[0], b[1], pad_idx) for b in train_dataloader),\n",
        "            model,\n",
        "            SimpleLossCompute(module.generator, criterion),\n",
        "            optimizer,\n",
        "            lr_scheduler,\n",
        "            mode=\"train+log\",\n",
        "            accum_iter=config[\"accum_iter\"],\n",
        "            train_state=train_state,\n",
        "        )\n",
        "\n",
        "        GPUtil.showUtilization() # GPU Auslastung anzeigen\n",
        "        if is_main_process:\n",
        "            file_path = \"%s%.2d.pt\" % (config[\"file_prefix\"], epoch)\n",
        "            torch.save(module.state_dict(), file_path)\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"[GPU{gpu}] Epoch {epoch} Validation ====\", flush=True)\n",
        "        model.eval()\n",
        "        sloss = run_epoch(\n",
        "            (Batch(b[0], b[1], pad_idx) for b in valid_dataloader),\n",
        "            model,\n",
        "            SimpleLossCompute(module.generator, criterion),\n",
        "            DummyOptimizer(),\n",
        "            DummyScheduler(),\n",
        "            mode=\"eval\",\n",
        "        )\n",
        "        print(sloss) # Verlust anzeigen\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    if is_main_process:\n",
        "        file_path = \"%sfinal.pt\" % config[\"file_prefix\"]\n",
        "        torch.save(module.state_dict(), file_path) # Modell speichern\n",
        "\n",
        "\n",
        "def train_distributed_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
        "    \"\"\"Verteiles Lernen\"\"\"\n",
        "    ngpus = torch.cuda.device_count()\n",
        "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "    os.environ[\"MASTER_PORT\"] = \"12356\"\n",
        "    print(f\"Number of GPUs detected: {ngpus}\")\n",
        "    print(\"Spawning training processes ...\")\n",
        "    mp.spawn(\n",
        "        train_worker,\n",
        "        nprocs=ngpus,\n",
        "        args=(ngpus, vocab_src, vocab_tgt, spacy_de, spacy_en, config, True),\n",
        "    )\n",
        "\n",
        "\n",
        "def train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
        "    \"\"\"Prüft ob parallelisiert trainiert werden soll\"\"\"\n",
        "    if config[\"distributed\"]:\n",
        "        train_distributed_model(\n",
        "            vocab_src, vocab_tgt, spacy_de, spacy_en, config\n",
        "        )\n",
        "    else:\n",
        "        train_worker(\n",
        "            0, 1, vocab_src, vocab_tgt, spacy_de, spacy_en, config, False\n",
        "        )\n",
        "\n",
        "\n",
        "def load_trained_model():\n",
        "    \"\"\"Erstellt bzw. lädt das trainierte Modell\"\"\"\n",
        "    config = {\n",
        "        \"batch_size\": 32,\n",
        "        \"distributed\": False,\n",
        "        \"num_epochs\": 8,\n",
        "        \"accum_iter\": 10,\n",
        "        \"base_lr\": 1.0,\n",
        "        \"max_padding\": 72,\n",
        "        \"warmup\": 3000,\n",
        "        \"file_prefix\": \"multi30k_model_\",\n",
        "    }\n",
        "    model_path = \"multi30k_model_final.pt\" # rel. Pfad für das Modell\n",
        "    if not exists(model_path):\n",
        "        train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config)\n",
        "\n",
        "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
        "    model.load_state_dict(torch.load(\"multi30k_model_final.pt\"))\n",
        "    return model\n",
        "\n",
        "model = load_trained_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Transformer Auswerten"
      ],
      "metadata": {
        "id": "cpBoZvZLW5mw"
      },
      "id": "cpBoZvZLW5mw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beispiel Sätze"
      ],
      "metadata": {
        "id": "t--VUtQPaCLS"
      },
      "id": "t--VUtQPaCLS"
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    \"\"\"Nehme Token mit höchster Wahrscheinlichkeit in jedem Schritt\"\"\"\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.zeros(1, 1).fill_(start_symbol).type_as(src.data)\n",
        "    for i in range(max_len - 1):\n",
        "        out = model.decode(\n",
        "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
        "        )\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data[0]\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.zeros(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
        "        )\n",
        "    return ys\n",
        "\n",
        "\n",
        "def check_outputs(\n",
        "    valid_dataloader,\n",
        "    model,\n",
        "    vocab_src,\n",
        "    vocab_tgt,\n",
        "    n_examples=15,\n",
        "    pad_idx=2,\n",
        "    eos_string=\"</s>\",\n",
        "):\n",
        "    results = [()] * n_examples\n",
        "    for idx in range(n_examples):\n",
        "        print(\"\\nExample %d ========\\n\" % idx)\n",
        "        b = next(iter(valid_dataloader))\n",
        "        rb = Batch(b[0], b[1], pad_idx)\n",
        "        greedy_decode(model, rb.src, rb.src_mask, 64, 0)[0]\n",
        "\n",
        "        src_tokens = [\n",
        "            vocab_src.get_itos()[x] for x in rb.src[0] if x != pad_idx\n",
        "        ]\n",
        "        tgt_tokens = [\n",
        "            vocab_tgt.get_itos()[x] for x in rb.tgt[0] if x != pad_idx\n",
        "        ]\n",
        "\n",
        "        print(\n",
        "            \"Source Text (Input)        : \"\n",
        "            + \" \".join(src_tokens).replace(\"\\n\", \"\")\n",
        "        )\n",
        "        print(\n",
        "            \"Target Text (Ground Truth) : \"\n",
        "            + \" \".join(tgt_tokens).replace(\"\\n\", \"\")\n",
        "        )\n",
        "        model_out = greedy_decode(model, rb.src, rb.src_mask, 72, 0)[0]\n",
        "        model_txt = (\n",
        "            \" \".join(\n",
        "                [vocab_tgt.get_itos()[x] for x in model_out if x != pad_idx]\n",
        "            ).split(eos_string, 1)[0]\n",
        "            + eos_string\n",
        "        )\n",
        "        print(\"Model Output               : \" + model_txt.replace(\"\\n\", \"\"))\n",
        "        results[idx] = (rb, src_tokens, tgt_tokens, model_out, model_txt)\n",
        "    return results\n",
        "\n",
        "\n",
        "def run_model_example(n_examples=5):\n",
        "    global vocab_src, vocab_tgt, spacy_de, spacy_en\n",
        "\n",
        "    print(\"Preparing Data ...\")\n",
        "    _, valid_dataloader = create_dataloaders(\n",
        "        torch.device(\"cpu\"),\n",
        "        vocab_src,\n",
        "        vocab_tgt,\n",
        "        spacy_de,\n",
        "        spacy_en,\n",
        "        batch_size=1,\n",
        "        is_distributed=False,\n",
        "    )\n",
        "\n",
        "    print(\"Loading Trained Model ...\")\n",
        "\n",
        "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
        "    model.load_state_dict(\n",
        "        torch.load(\"multi30k_model_final.pt\", map_location=torch.device(\"cpu\"))\n",
        "    )\n",
        "\n",
        "    print(\"Checking Model Outputs:\")\n",
        "    example_data = check_outputs(\n",
        "        valid_dataloader, model, vocab_src, vocab_tgt, n_examples=n_examples\n",
        "    )\n",
        "    return model, example_data\n",
        "\n",
        "\n",
        "execute_example(run_model_example)"
      ],
      "metadata": {
        "id": "pH6xpkR7aFnL",
        "outputId": "3c271220-c0a8-493a-ccae-129fd24cea98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pH6xpkR7aFnL",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing Data ...\n",
            "Loading Trained Model ...\n",
            "Checking Model Outputs:\n",
            "\n",
            "Example 0 ========\n",
            "\n",
            "Source Text (Input)        : <s> Eine Frau in einem blauen T-Shirt spielt ein Instrument . </s>\n",
            "Target Text (Ground Truth) : <s> A woman in a blue shirt is playing an instrument . </s>\n",
            "Model Output               : <s> A woman in a blue shirt is playing an instrument . </s>\n",
            "\n",
            "Example 1 ========\n",
            "\n",
            "Source Text (Input)        : <s> Eine Person beim Parasailing über einem großen Gewässer . </s>\n",
            "Target Text (Ground Truth) : <s> A person is parasailing over a large body of water . </s>\n",
            "Model Output               : <s> A person is parasailing over a large body of water . </s>\n",
            "\n",
            "Example 2 ========\n",
            "\n",
            "Source Text (Input)        : <s> Viele Stühle sind leer und nur einige wenige Menschen genießen die Sonne . </s>\n",
            "Target Text (Ground Truth) : <s> Many of the chairs are empty with only a few people enjoying the sun . </s>\n",
            "Model Output               : <s> Many people are in the same time and some people enjoy the sun . </s>\n",
            "\n",
            "Example 3 ========\n",
            "\n",
            "Source Text (Input)        : <s> Ein Mann in einem schwarz-weiß gestreiften T-Shirt fotografiert eine Frau an einem Springbrunnen . </s>\n",
            "Target Text (Ground Truth) : <s> A man in a black and white striped shirt photographing a woman by a fountain . </s>\n",
            "Model Output               : <s> A man in a black and white - striped shirt is taking a picture of a fountain . </s>\n",
            "\n",
            "Example 4 ========\n",
            "\n",
            "Source Text (Input)        : <s> Ein gelbes Auto saust über ein schneebedecktes Feld . </s>\n",
            "Target Text (Ground Truth) : <s> A yellow car speeds along a snowy field . </s>\n",
            "Model Output               : <s> A yellow car is <unk> through a snowy field . </s>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-",
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}